<h2>Big Data Technologies - <i>Introduction to Spark SQL in Python</i> 
  <a href="https://nbviewer.jupyter.org/github/Williamdst/Springboard-DSC/blob/master/Coursework/25.2_Apache-Spark/Spark-DataFrames.ipynb">
    <img align='center' src="https://img.shields.io/badge/Jupyter-F37626.svg?&style=for-the-badge&logo=Jupyter&logoColor=white" width='53' />
  </a>
</h2>
PySpark is the Python API written in python to support Apache Spark. Apache Spark is a distributed framework that can handle Big Data analysis. Spark is basically a computational engine, that works with huge sets of data by processing them in parallel and batch systems. <br> </br>

In this case study I learned about Spark Dataframes and how to do basic operations such as filtering and aggregations using the "built-in" functions as well as SQL. From there I looked at basic EDA and applied machine learning on the dataframes. 

<h2>Reflection</h2>
<ol>
  <li>The PySpark dataframe is very similar to the Pandas dataframe and the operations were very similar. Getting things done really is just a matter of syntax.</li>
  <li>Something that I want to explore further is integrating Apache Spark into pipelines that actually have Big Data. </li>
</ol>

